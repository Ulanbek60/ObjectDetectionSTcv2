import cv2
import numpy as np

cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É")
    exit()

print("üé• –î–µ—Ç–µ–∫—Ç–æ—Ä –¥–≤–∏–∂–µ–Ω–∏—è –∑–∞–ø—É—â–µ–Ω")
print(" [s] ‚Äî —Å–¥–µ–ª–∞—Ç—å —Å–Ω–∏–º–æ–∫ –¥–≤–∏–∂–µ–Ω–∏—è")
print(" [r] ‚Äî —Å–±—Ä–æ—Å —Ñ–æ–Ω–∞")
print(" [q] ‚Äî –≤—ã—Ö–æ–¥")

ret, frame1 = cap.read()
ret, frame2 = cap.read()

sensitivity = 40 # 0-255
min_area = 500

while True:
    diff = cv2.absdiff(frame1, frame2)

    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)

    blur = cv2.GaussianBlur(gray, ksize=(5, 5), sigmaX=0)

    _, thresh = cv2.threshold(src=blur, thresh=sensitivity, maxval=255, type=cv2.THRESH_BINARY)

    dilated = cv2.dilate(thresh, kernel=None, iterations=3)

    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

    display_frame = frame1.copy()

    motion_detected = False

    for contour in contours:
        area = cv2.contourArea(contour)

        if area < min_area:
            continue

        motion_detected = True

        x, y, w, h = cv2.boundingRect(contour)

        cv2.rectangle(display_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

        cv2.putText(display_frame, f"Area: {int(area)}", (x, y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

    status = "Motion detected!" if motion_detected else "No motion"
    color = (0, 0, 255) if motion_detected else (0, 255, 0)

    cv2.putText(display_frame, status, (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

    cv2.putText(display_frame, f"Sensitivity: {sensitivity}", (10, 60),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)

    cv2.imshow(winname='Motion detector', mat=display_frame)
    cv2.imshow(winname='Threshold (debugging)', mat=thresh)

    key = cv2.waitKey(1) & 0xFF

    if key == ord('q'):
        print("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
        break
    elif key == ord('s'):
        filename = f"motion_{cv2.getTickCount()}.jpg"
        cv2.imwrite(filename, display_frame)
        print(f"üì∑ –°–Ω–∏–º–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
    elif key == ord('r'):
        print("üîÑ –°–±—Ä–æ—Å —Ñ–æ–Ω–æ–≤–æ–≥–æ –∫–∞–¥—Ä–∞")
        ret, frame1 = cap.read()
        ret, frame2 = cap.read()
        continue
    elif key == ord('+') or key == ord('='):
        sensitivity = min(sensitivity + 5, 100)
        print(f"–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {sensitivity}")
    elif key == ord('-'):
        sensitivity = max(sensitivity - 5, 5)
        print(f"–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {sensitivity}")

    frame1 = frame2
    ret, frame2 = cap.read()

    if not ret:
        print("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–¥—Ä–∞.")
        break

cap.release()
cv2.destroyAllWindows()
